You are will be creating code in python for an AI application.

You will be given User Specifications in JSON format.
It include the following fields:
    "app_name": app_name,
    "user_name": user_name,
    "user_major": user_major,
    "user_graduation": user_graduation,
    "chatbot_type": chatbot_type,
    "use_RAG": use_RAG,
    "use_web": use_web,
    "specifications": """""",
    "file_upload": file_metadata

We will be using the following stack:
- Streamlit for the UI and app logic
- Gemini Flash for the AI chatbot
- Langchain for conversational AI

Set the title of the Streamlit app to the app_name.
 
st.title(app_name)

Create a session_state variable to store the chat history.

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": ""}]

Create a text input field for the user to type their queries.

if prompt := st.chat_input("What classes should I take if I want to become...?"):

    with st.chat_message("user", avatar="*put a relevant emoji here*"):
            st.markdown(prompt)
        
    # add to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})

    # call response generator
    with st.chat_message("assistant", avatar="âœ¨"):
        with st.spinner("Thinking..."):
            response = st.write_stream(st.session_state.chatBot.chat_stream(prompt))

        st.session_state.messages.append({"role": "assistant", "content": response})


Generate a Streamlit app code for an AI chatbot. 
The UI should include a simple text entry field where users can type their queries, and the chatbot should display responses accordingly. 
The code should be generated based on the following user specifications (provided in JSON format) and should only use file metadata, not the full file content. 
Include necessary comments to explain the code logic.

# Create the model instance using Gemini Flash, including the detailed system instruction.
    model = genai.GenerativeModel(
        model_name="gemini-2.0-flash",
        generation_config=generation_config,
        system_instruction=system_instruction,
    )
    
 - Get the API Key from the .env file and configure the Gemini API key."
    # Load environment variables from a .env file

    load_dotenv()
    # The GEMINI_API_KEY should be defined in your .env file.
    api_key = os.getenv("GEMINI_API_KEY")"""
    try:
        response = chat_session.send_message(message)
        return response.text
    except Exception as e:
        return f"# Error calling Gemini Flash API: {e}

Always use gemini-2.0-flash model for the chatbot.


The finalized chatbot should have file uploading built in the streamlit. 
The file should be an audit from the user as their degree.
Here is the code to copy:

uploaded_file = st.file_uploader("Upload your audit:", type=["pdf", "txt"])

Then convert this audit to text.
The text conversion should be from the package import line:

from pypdf import pdfreader.

Then, keep the audit message in the chat session combined with any user requests but don't show it being added to the chat.
This way, Gemini is updated on the user's audit after submission and can help the user with
their audit more effeciently.

When storing the audit as text, make sure to follow Gemini's chat history format:
{"role": "user", "parts": [{"text": "PDF text goes here"}]}

The first message in the state from:
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": ""}]

Content should be combined with the User Specification at the end of this message 
to have a personalized opening message.

